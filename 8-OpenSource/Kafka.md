## 一、介绍

### 1、Apache Kafak是一个分布式流处理平台，这到底意味着什么？

#### 1)、我们知道流处理平台有以下三个特性：

1. 可以发布和订阅流式记录。这一方面与消息队列或企业消息系统类似
2. 可以存储流式的记录，并有较好的容错性
3. 可以在流式记录产生时进行处理

#### 2)、kafka适合什么场景？

它可以用于两大类别应用：

1. **构造实时流数据管道**，它可以在系统或应用之间可靠地获取数据(类似:Message Queue)
2. **构建实时流式应用程序**，对这些流数据进行转换或者影响(就是流处理，通过kafka stream和topic之间内部进行变化)

#### 3)、基本概念

![kafka概念](https://kafka.apachecn.org/10/images/kafka-apis.png)

##### (1)、概念

- Kafka作为一个集群，运行在一台或者多台服务器上
- Kafak通过`topic`对存储的流数据进行分类
- 每条记录中包含一个`key`，一个`value`和一个`timestamp`(时间戳)

##### (2)、4个核心API

- <b style="color:deeppink;">Producer API</b> 允许一个应用程序发布一串流式的数据到一个或者多个`Kafka Topic`。
- <b style="color:deeppink;">Consumer API</b> 允许一个应用程序订阅一个或多个`Topic`，并且对发布给他们的流式数据进行处理
- <b style="color:deeppink;">Streams API</b> 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个`topic`中去，在输入输出流中进行有效的转换。
- <b style="color:deeppink;">Connector API允许</b> 构建并运行可以重用的`生产者`或者`消费者`，将`Kafka topics`连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表(table)的所有变更内容。

### 2、Topics和日志

让我们首先深入了解下Kafka的核心概念:提供一串流式的记录— topic 。

Topic就是数据主题，是数据记录发布的地方，可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，<u>一个topic可以拥有有个或者多个消费者来订阅它的数据</u>。对于每一个`topic`，kafka集群都会维持一个分区日志，如下所示：

![kafka topic分区日志](https://kafka.apachecn.org/10/images/log_anatomy.png)

每个分区都是有序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，我们称为offset，offset用来唯一的标识分区中每一条记录。

Kafka集群保留所有发布的记录，无论他们是否被消费，通过一个可配置的参数，保留期限来控制。举个例子，如果保留策略设置为2天，一条记录发布后两天内，可以随机被消费，两天过后这条记录会被抛弃并释放磁盘空间。Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题。

![](https://kafka.apachecn.org/10/images/log_consumer.png)

事实上，每一个消费者中唯一保存的元数据是offset(偏移量)，即消费在log中的位置。偏移量由消费者所控制：<b>通常在读取记录后，消费者会以线性的方式增加偏移量，但是实际上，由于这个 位置由消费者控制，所以消费者可以采用任何顺序来消费记录</b>。例如，<u>一个消费者可以重置到一个旧的偏移量，从而重新处理过去的数据；也可以跳过最近的记录，从“现在”开始消费</u>。

这些细节说明Kafka的消费者是非常廉价的，消费者的增加和减少，对集群或者其它消费都没有多大的影响。比如，你可以使用命令行工具，对一些topic内容执行tail操作，并不会影响已存在的消费者数据。

日志中的partition(分区)有以下几个用途

1. 日日志大小超过单台服务器限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据。
2. 可以作为并行的单元

### 3、分布式

日志的分区partition(分布)在Kafak集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。

每个分区都有一台server作为"leader"，零台或多台作。为"follwers"。leader server处理一切对partition(分区)的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，follwers中的一台服务器会自动成为新的leader。每台server都会成为某些分区的leader和某些分区的follower，因此集群的负载是平衡的。

### 4、生产者

生产者可以将数据发布到选择的topic中，生产者负责将记录分配到topic的哪一个partition(分区)中。可以使用循环的方式来简单地实现负载均衡，也可以根据某些语义分区函数(例如：记录中的key)来完成。

### 5、消费者

消费者使用一个“消费组”名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例。消弱者实例可以分布在多个进程中或者多个机器上。

- 如果所有的消费者实例在同一消费组中，消息会负载平衡到每一个消费者实例

- 如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程。

![](https://kafka.apachecn.org/10/images/consumer-groups.png)

如图，这个 Kafka 集群有两台 server 的，四个分区(p0-p3)和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。

通常情况下，每个topic都会有一些消费组，一个消费组对应一个“逻辑订阅者”。一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个进程。

在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些 partition 分区;如果一个实例消失，拥有的分区将被分发到剩余的实例。

Kafka 只保证分区内的记录是有序的，而不保证主题中不同分区的顺序。每个 partition 分区按照key值排序足以满足大多数应用程序的需求。但如果你需要总记录在所有记录的上面，可使用仅有一个分区的主题来实现，这意味着每个消费者组只有一个消费者进程。

<b>注意：<span style="color:deeppink;">同一个组中的消费者不能同时间消费不同分区的数据</span></b>

### 6、保证

high-level Kafka给予以下保证:

- 生产者发送到特定topic partition的消息将按照发送的顺序处理。也就是说，如果记录M1和记录M2由相同的生产者发送，先发送M1记录，那么M1的偏移比M2小，并在日志中较早出现。
- 一个消费者实例按照日志中的顺序查询记录
- 对于具有N个副本的主题，我们最多容忍N-1个服务器故障，从而保证不会丢失任何提交到日志中的记录。

### 7、Kafka作为消息系统

Kafka Streams的概念与传统的企业消息系统相比如何？

传统的消息系统有两个模块：`队列`和`发布-订阅`。在`队列`中，消费者池从server读取数据，每条记录被池子中的一个消费者消费；在`发布-订阅`中，记录被广播到所有的消费者。两者均有优缺点。队列的优点在于它允许你将处理数据过程分给多个消费者实例，使你可以扩展处理过程。不好的是。队列不是多订阅者模式，一旦一个进程读取了数据，数据就会被丢弃。而发布-订阅系统允许你广播数据到多个进程，但是无法进行扩展处理，因为每条消息都会发送给所有的订阅者。

消费组在Kafka有两层概念。在`队列`中，消费组允许你将处理过程分发给一系列进程(消费组中的成员)。在`发布-订阅`中，Kafka允许你将消息广播给多个消费组。

Kafka的优势在于每个topic都有以下特性—可以扩展处理并且允许多订阅者模式—不需要只选择其中一个.

Kafka相比于传统消息队列还具有更严格的顺序保证

传统队列在服务器上保存有序的记录，如果多个消费者消费队列中的数据， 服务器将按照存储顺序输出记录。虽然服务器按顺序输出记录，但是记录被异步传递给消费者，因此记录可能会无序到达不同的消费者。这意味着在并行消耗情况下，记录的顺序是丢失的。因此消息系统通常使用“唯一消费者”的概念，即只让一个进程从队列中消费，但这就意味着不能够并行地处理数据。

`topic`中的`partition`是一个并行的概念。Kafka能够为一个消费者池提供顺序保证和负载平衡，是通过将topic中的partition分配给消费者组中的消费者来实现的，以便每个分区由消费组中的一个消费者消耗。通过这样，我们能够确保消费者是该分区的唯一读者，并按顺序消费数据。从多分区保证了多个消费者实例间的负载均衡。**但请注意，消费者组中的消费者实例个数不能超过分区的数量**。

### 8、Kafka作为存储系统

许多消息队列可以发布消息，除了消费消息之外还可以充当中间数据的存储系统。那么Kafka作为一个优秀的存储系统有什么不同呢?

数据写入Kafka后被写入到磁盘，并进行备份以便容错。直到完全务份，Kafka才让生产者认为完成写入，即使写入失败Kafka也会确保继续写入。

Kafka50TB使用磁盘结构，具有很好的扩展性，50kb和50TB的数据在server上表现一致。

可以存储大量的数据，并且可通过客户端控制它读取数据的位置，<i style="color:deeppink;">你可认为Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统</i>。

### 9、Kafka作为流处理

将消息、存储和流处理结合起来，使得Kafka看上去不一般，但这是它作为流平台所备的.

像HDFS这样的分布式文件系统可以存储用于批处理的静态文件。 一个系统如果可以存储和处理历史数据是非常不错的。

例如，零售应用程序可能会接收销售和出货的输入流，经过价格调整计算后，再输出一串流式数据。

简单的数据处理可以直接用生产者和消费者的API。对于复杂的数据变换，Kafka提供了Streams API。Stream API允许应用做一些复杂的处理，比如将流数据聚合或者join。

这一功能有助于解决以下这种应用程序所面临的问题：处理无序数据，当消费端代码变更后重新处理输入，执行状态计算等。

Streams API建立在Kafka的核心之上：它使用Producer和Consumer API作为输入，使用Kafka进行有状态的存储， 并在流处理器实例之间使用相同的消费组机制来实现容错。

### 10、批处理

将消息、存储和流处理结合起来，使得Kafka看上去不一般，但这是它作为流平台所备的.

像HDFS这样的分布式文件系统可以存储用于批处理的静态文件。 一个系统如果可以存储和处理历史数据是非常不错的。

传统的企业消息系统允许处理订阅后到达的数据。以这种方式来构建应用程序，并用它来处理即将到达的数据。

Kafka结合了上面所说的两种特性。作为一个流应用程序平台或者流数据管道，这两个特性，对于Kafka 来说是至关重要的。

通过组合存储和低延迟订阅，流式应用程序可以以同样的方式处理过去和未来的数据。 一个单一的应用程序可以处理历史记录的数据，并且可以持续不断地处理以后到达的数据，而不是在到达最后一条记录时结束进程。 这是一个广泛的流处理概念，其中包含批处理以及消息驱动应用程序

同样，作为流数据管道，能够订阅实时事件使得Kafk具有非常低的延迟; 同时Kafka还具有可靠存储数据的特性，可用来存储重要的支付数据， 或者与离线系统进行交互，系统可间歇性地加载数据，也可在停机维护后再次加载数据。流处理功能使得数据可以在到达时转换数据。

## 二、安装及集群

